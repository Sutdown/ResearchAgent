# ä»£ç ç¤ºä¾‹ï¼šRAG ChatBot å®Œæ•´å®ç°ï¼ˆç»“æ„ï¼‰

print("=== RAG ChatBot å®Œæ•´é¡¹ç›® ===\n")

# é¡¹ç›®ç»“æ„
print("1. é¡¹ç›®ç»“æ„:")
print("""
rag-chatbot/
â”œâ”€â”€ .env                    # ç¯å¢ƒå˜é‡
â”œâ”€â”€ requirements.txt        # ä¾èµ–
â”œâ”€â”€ app.py                  # Streamlit åº”ç”¨
â”œâ”€â”€ rag/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ embeddings.py      # åµŒå…¥ç”Ÿæˆ
â”‚   â”œâ”€â”€ vector_store.py    # å‘é‡æ•°æ®åº“
â”‚   â””â”€â”€ retriever.py       # æ£€ç´¢å™¨
â”œâ”€â”€ data/
â”‚   â””â”€â”€ documents/         # çŸ¥è¯†åº“æ–‡æ¡£
â””â”€â”€ logs/
    â””â”€â”€ app.log            # æ—¥å¿—
""")

# æ ¸å¿ƒä»£ç 
print("\n2. æ ¸å¿ƒå®ç°:")
print("""
# embeddings.py
from openai import OpenAI

class EmbeddingGenerator:
    def __init__(self, api_key):
        self.client = OpenAI(api_key=api_key)

    def generate(self, text):
        response = self.client.embeddings.create(
            model="text-embedding-ada-002",
            input=text
        )
        return response.data[0].embedding


# vector_store.py
import chromadb

class VectorStore:
    def __init__(self, persist_dir="./chroma_db"):
        self.client = chromadb.Client(...)
        self.collection = self.client.get_or_create_collection("docs")

    def add_documents(self, documents, metadatas=None):
        self.collection.add(documents=documents, metadatas=metadatas)

    def query(self, query_text, n_results=3):
        return self.collection.query(query_texts=[query_text], n_results=n_results)


# retriever.py
class RAGRetriever:
    def __init__(self, vector_store, llm):
        self.vector_store = vector_store
        self.llm = llm

    def retrieve_and_generate(self, query):
        # 1. æ£€ç´¢ç›¸å…³æ–‡æ¡£
        results = self.vector_store.query(query, n_results=3)
        context = "\\n".join(results['documents'][0])

        # 2. æ„å»ºæç¤ºè¯
        prompt = f'''
åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜ï¼š

ä¸Šä¸‹æ–‡ï¼š
{context}

é—®é¢˜ï¼š{query}

å›ç­”ï¼š'''

        # 3. ç”Ÿæˆå›ç­”
        response = self.llm.generate(prompt)
        return {
            "answer": response,
            "sources": results['documents'][0]
        }


# app.py (Streamlit åº”ç”¨)
import streamlit as st
from rag import RAGRetriever, VectorStore, EmbeddingGenerator

st.title("ğŸ¤– RAG ChatBot")

# åˆå§‹åŒ–
if "retriever" not in st.session_state:
    vector_store = VectorStore()
    retriever = RAGRetriever(vector_store, llm)
    st.session_state.retriever = retriever

# èŠå¤©ç•Œé¢
if prompt := st.chat_input("è¾“å…¥ä½ çš„é—®é¢˜..."):
    result = st.session_state.retriever.retrieve_and_generate(prompt)

    st.write(result["answer"])
    with st.expander("ğŸ“š å‚è€ƒæ¥æº"):
        for source in result["sources"]:
            st.write(f"- {source}")
""")

# å·¥ä½œæµç¨‹
print("\n3. RAG å·¥ä½œæµç¨‹:")
print("""
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  ç”¨æˆ·æé—®       â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ ç”ŸæˆæŸ¥è¯¢åµŒå…¥    â”‚ â† OpenAI Embeddings
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ å‘é‡ç›¸ä¼¼åº¦æœç´¢  â”‚ â† ChromaDB
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ æ£€ç´¢Top-Kæ–‡æ¡£   â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ æ„å»ºæç¤ºè¯      â”‚ â† Query + Context
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ LLM ç”Ÿæˆå›ç­”    â”‚ â† OpenAI GPT-4
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ è¿”å›ç­”æ¡ˆ+æ¥æº   â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
""")

# æŠ€æœ¯æ ˆ
print("\n4. å®Œæ•´æŠ€æœ¯æ ˆ:")
print("""
  ğŸ”¹ UI æ¡†æ¶: Streamlit
  ğŸ”¹ Agent æ¡†æ¶: LangGraph
  ğŸ”¹ LLM: OpenAI GPT-4
  ğŸ”¹ Embeddings: OpenAI text-embedding-ada-002
  ğŸ”¹ å‘é‡æ•°æ®åº“: ChromaDB
  ğŸ”¹ æ•°æ®åˆ†æ: Pandas
  ğŸ”¹ å¯è§†åŒ–: Matplotlib/Plotly
  ğŸ”¹ æ—¥å¿—: Python logging
  ğŸ”¹ ç¯å¢ƒç®¡ç†: python-dotenv
  ğŸ”¹ éƒ¨ç½²: Docker + Streamlit Cloud
""")