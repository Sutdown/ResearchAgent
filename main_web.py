from __future__ import annotations

import os
import time
import threading
from datetime import datetime
from pathlib import Path
from typing import Dict, Any

import gradio as gr
from dotenv import load_dotenv

# ===== åŸæœ‰ç³»ç»Ÿä¾èµ– =====
from RAgents.agents.conversation import ConversationManager
from RAgents.agents.coordinator import Coordinator
from RAgents.agents.planner import Planner
from RAgents.agents.rapporteur import Rapporteur
from RAgents.agents.researcher import Researcher
from RAgents.llms.factory import LLMFactory
from RAgents.workflow.graph import ResearchWorkflow
from RAgents.utils.config import load_config_from_env
from RAgents.utils.logger import setup_logger
from RAgents.langsmith.langsmith import setup_langsmith_tracing

# ======================
# å…¨å±€çŠ¶æ€ï¼ˆWeb ä¸“ç”¨ï¼‰
# ======================
log_buffer: list[str] = []

approval_state = {
    "waiting": False,
    "approved": None,
    "feedback": None
}

final_report_holder = {
    "report": None
}

# ======================
# å·¥å…·å‡½æ•°
# ======================
def log(msg: str):
    log_buffer.append(msg)

def reset_state():
    log_buffer.clear()
    approval_state.update({
        "waiting": False,
        "approved": None,
        "feedback": None
    })
    final_report_holder["report"] = None

# ======================
# Web ç‰ˆäººå·¥å®¡æ‰¹å›è°ƒ
# ======================
def human_approval_callback(state: Dict[str, Any]):
    log("\nğŸŸ¡ ç­‰å¾…äººå·¥å®¡æ‰¹...\n")
    approval_state["waiting"] = True

    while approval_state["approved"] is None:
        time.sleep(0.2)

    approval_state["waiting"] = False

    if approval_state["approved"]:
        log("âœ… ç ”ç©¶è®¡åˆ’å·²æ‰¹å‡†\n")
        return True, None
    else:
        feedback = approval_state["feedback"] or "è¯·é‡æ–°ä¼˜åŒ–ç ”ç©¶è®¡åˆ’"
        log(f"âŒ è®¡åˆ’è¢«æ‹’ç»ï¼Œåé¦ˆï¼š{feedback}\n")
        return False, feedback

# ======================
# Web ç ”ç©¶æ‰§è¡Œå‡½æ•°ï¼ˆæ ¸å¿ƒï¼‰
# ======================
def run_research_web(
    query: str,
    provider: str,
    model: str,
    max_iterations: int,
    auto_approve: bool,
    output_format: str
):
    reset_state()
    yield ""

    if not query.strip():
        yield "âŒ ç ”ç©¶é—®é¢˜ä¸èƒ½ä¸ºç©º"
        return

    def task():
        try:
            setup_logger()
            setup_langsmith_tracing()
            load_dotenv()

            env_cfg = load_config_from_env()
            os.environ["LLM_PROVIDER"] = provider
            env_cfg = load_config_from_env()
            env_cfg.llm.model = model
            env_cfg.workflow.max_iterations = max_iterations
            env_cfg.workflow.auto_approve_plan = auto_approve

            log(f"ğŸš€ ä½¿ç”¨æ¨¡å‹ï¼š{provider.upper()} / {model}\n")

            llm = LLMFactory.create_llm(
                provider=env_cfg.llm.provider,
                api_key=env_cfg.llm.api_key,
                model=env_cfg.llm.model
            )

            coordinator = Coordinator(llm)
            planner = Planner(llm)

            researcher = Researcher(
                llm=llm,
                tavily_api_key=env_cfg.search.tavily_api_key,
                mcp_server_url=env_cfg.search.mcp_server_url,
                mcp_api_key=env_cfg.search.mcp_api_key,
                enable_vector_memory=False,
                vector_memory_path="./vector_memory"
            )

            def stream_callback(chunk: str):
                if chunk:
                    log(chunk)

            rapporteur = Rapporteur(llm, stream_callback=stream_callback)

            workflow = ResearchWorkflow(
                coordinator,
                planner,
                researcher,
                rapporteur,
                langsmith_config=env_cfg.langsmith
            )

            stream = workflow.stream_interactive(
                query=query,
                max_iterations=max_iterations,
                auto_approve=auto_approve,
                human_approval_callback=None if auto_approve else human_approval_callback,
                output_format=output_format
            )

            current_state = None

            for update in stream:
                for _, state in update.items():
                    if isinstance(state, dict):
                        current_state = state

            if current_state and current_state.get("final_report"):
                final_report_holder["report"] = current_state["final_report"]

                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                out_dir = Path("./outputs")
                out_dir.mkdir(exist_ok=True)

                suffix = "html" if output_format == "html" else "md"
                path = out_dir / f"research_{timestamp}.{suffix}"
                rapporteur.save_report(final_report_holder["report"], str(path))

                log(f"\nğŸ“„ æŠ¥å‘Šå·²ä¿å­˜ï¼š{path}\n")

        except Exception as e:
            log(f"\nâŒ å‘ç”Ÿé”™è¯¯ï¼š{e}\n")

    threading.Thread(target=task, daemon=True).start()

    while True:
        time.sleep(0.3)
        yield "\n".join(log_buffer)

# ======================
# å®¡æ‰¹æŒ‰é’®
# ======================
def approve_plan():
    approval_state["approved"] = True
    return "âœ… å·²æ‰¹å‡†"

def reject_plan(feedback):
    approval_state["approved"] = False
    approval_state["feedback"] = feedback
    return "âŒ å·²æ‹’ç»"

# ======================
# Gradio UI
# ======================
with gr.Blocks(title="Deep Researchç ”ç©¶ç³»ç»Ÿ") as demo:
    gr.Markdown("# ğŸ§  Deep Research System")

    with gr.Row():
        query = gr.Textbox(label="ç ”ç©¶é—®é¢˜", lines=3)
        provider = gr.Dropdown(
            ["deepseek", "openai", "claude", "gemini"],
            value="deepseek",
            label="LLM Provider"
        )

    model = gr.Textbox(label="æ¨¡å‹åç§°", value="deepseek-chat")
    max_iter = gr.Slider(1, 10, value=5, step=1, label="æœ€å¤§è¿­ä»£æ¬¡æ•°")
    auto = gr.Checkbox(label="è‡ªåŠ¨æ‰¹å‡†ç ”ç©¶è®¡åˆ’", value=False)
    output_format = gr.Radio(["md", "html"], value="md", label="è¾“å‡ºæ ¼å¼")

    start_btn = gr.Button("ğŸš€ å¼€å§‹ç ”ç©¶")

    log_box = gr.Textbox(
        label="è¿è¡Œæ—¥å¿—ï¼ˆå®æ—¶ï¼‰",
        lines=20,
        interactive=False
    )

    gr.Markdown("## ğŸ‘¤ äººå·¥å®¡æ‰¹ï¼ˆä»…åœ¨å…³é—­è‡ªåŠ¨æ‰¹å‡†æ—¶ç”Ÿæ•ˆï¼‰")

    feedback_box = gr.Textbox(label="æ‹’ç»åé¦ˆï¼ˆå¯é€‰ï¼‰")
    with gr.Row():
        approve_btn = gr.Button("âœ… æ‰¹å‡†")
        reject_btn = gr.Button("âŒ æ‹’ç»")

    approve_btn.click(approve_plan, outputs=log_box)
    reject_btn.click(reject_plan, inputs=feedback_box, outputs=log_box)

    start_btn.click(
        run_research_web,
        inputs=[query, provider, model, max_iter, auto, output_format],
        outputs=log_box
    )

demo.launch()
