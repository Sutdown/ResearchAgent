from datetime import datetime
from typing import Dict, Any, List
from rich.console import Console
import re

from RAgents.llms.factory import LLMFactory
from RAgents.prompts.loader import PromptLoader
from RAgents.tools.arxiv_search import ArxivSearch
from RAgents.tools.mcp_client import MCPClient
from RAgents.tools.tavily_search import TavilySearch
from RAgents.utils.vector import VectorMemory

console = Console()

class ConversationManager:
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.conversation_history = []
        self.session_id = datetime.now().strftime('%Y%m%d_%H%M%S')
        # åˆ›å»ºLLMå®ä¾‹
        self.llm = LLMFactory.create_llm(
            provider=config['llm_provider'],
            api_key=config['llm_api_key'],
            model=config['llm_model']
        )
        self.prompt_loader = PromptLoader()
        # åˆ›å»ºå·¥å…·å®ä¾‹
        self.tavily = TavilySearch(config.get('tavily_api_key')) if config.get('tavily_api_key') else None
        self.arxiv = ArxivSearch()
        self.mcp = MCPClient(config.get('mcp_server_url'), config.get('mcp_api_key')) if config.get('mcp_server_url') else None
        # åˆ›å»ºå‘é‡åº“å®ä¾‹
        self.vector_memory = VectorMemory(persist_directory=config.get('vector_memory_path', './vector_memory'))
        # å¯¹è¯é•¿åº¦ç®¡ç†
        self.context_window = 5 # ä¸Šä¸‹æ–‡çª—å£å¤§å°
        self.relevance_threshold = 0.8 # ç›¸ä¼¼åº¦é˜ˆå€¼

    def start_conversation(self) -> bool | None:
        console.print("\n[bold cyan]ğŸ¤– Deep-Researchå¤šè½®å¯¹è¯ç³»ç»Ÿ[/bold cyan]")
        console.print("[yellow]æˆ‘å¯ä»¥åŸºäºå†å²ç ”ç©¶æŠ¥å‘Šå’Œå¯ç”¨å·¥å…·ä¸æ‚¨å¯¹è¯[/yellow]")
        console.print("[dim]è¾“å…¥ 'exit' æˆ– 'quit' æˆ– 'é€€å‡º' ç»“æŸå¯¹è¯[/dim]\n")

        while True:
            try:
                user_input = console.input("[bold blue]ç”¨æˆ·:[/bold blue] ").strip()
                if self._is_exit_command(user_input):
                    console.print("\n[yellow]æ„Ÿè°¢ä½¿ç”¨ï¼[/yellow]\n")
                    return True
                if not user_input:
                    continue
                self._process_user_input(user_input) # å¤„ç†ç”¨æˆ·è¾“å…¥
            except KeyboardInterrupt:
                console.print("\n\n[yellow]å¯¹è¯è¢«ä¸­æ–­[/yellow]\n")
                return False
            except Exception as e:
                console.print(f"[red]å¯¹è¯å‘ç”Ÿé”™è¯¯ï¼š{e}[/red]")

    def _is_exit_command(self, user_input: str) -> bool:
        exit_commands = ['exit', 'quit', 'é€€å‡º', 'ç»“æŸ', 'bye', 'goodbye']
        return user_input.lower().strip() in exit_commands

    def _process_user_input(self, user_input: str) -> None:
        # å°†ç”¨æˆ·è¾“å…¥æ·»åŠ åˆ°å¯¹è¯å†å²ä¸­
        self.conversation_history.append({
            'role': 'user',
            'content': user_input,
            'timestamp': datetime.now().isoformat()
        })

        # å¤„ç†ç”¨æˆ·è¾“å…¥
        try:
            intent = self._analyze_intent(user_input)

            if intent == 'simple_search':
                # ç›´æ¥æœç´¢
                response = self._handle_direct_search(user_input)
            elif intent == 'complex_research':
                # å¤æ‚ç ”ç©¶
                response = self._handle_complex_research(user_input)
            else:
                # é»˜è®¤å¯¹è¯æ¨¡å¼
                response = self._handle_conversation_query(user_input)

            console.print(f"[bold green]ç³»ç»Ÿ:[/bold green] {response}")
            self.conversation_history.append({
                'role': 'assistant',
                'content': response,
                'timestamp': datetime.now().isoformat()
            })
        except Exception as e:
            error_msg = f"å¤„ç†è¯·æ±‚æ—¶å‡ºé”™: {str(e)}"
            console.print(f"[red]{error_msg}[/red]")
            self.conversation_history.append({
                'role': 'assistant',
                'content': error_msg,
                'timestamp': datetime.now().isoformat()
            })

    # åˆ†æç”¨æˆ·æ„å›¾
    def _analyze_intent(self, user_input: str) -> str:
        """åˆ†æç”¨æˆ·æ„å›¾"""
        # Simple keywords for search
        search_keywords = [
            'æœç´¢', 'search', 'æŸ¥æ‰¾', 'find', 'æœ€æ–°', 'latest',
            'æ–°é—»', 'news', 'è®ºæ–‡', 'paper', 'ç ”ç©¶', 'research'
        ]
        # Complex research indicators
        research_indicators = [
            'åˆ†æ', 'analyze', 'è¯¦ç»†ç ”ç©¶', 'detailed research',
            'å…¨é¢', 'comprehensive', 'æ·±å…¥', 'in-depth'
        ]
        input_lower = user_input.lower()

        if any(keyword in input_lower for keyword in search_keywords):
            if any(indicator in input_lower for indicator in research_indicators):
                return 'complex_research'
            return 'simple_search'

        if any(indicator in input_lower for indicator in research_indicators):
            return 'complex_research'

        return 'conversation'

    # å¤„ç†ç›´æ¥æœç´¢ï¼Œæœ‰æ˜ç¡®çš„æœç´¢é—®é¢˜çš„æƒ…å†µï¼Œé‡‡ç”¨å·¥å…·æœç´¢
    def _handle_direct_search(self, user_input: str) -> str:
        search_query = self._extract_search_query(user_input)

        if not search_query:
            return "è¯·æä¾›æ›´æ˜ç¡®çš„æœç´¢å†…å®¹ã€‚"

        if self.tavily:
            try:
                results = self.tavily.search(search_query, max_results=3)
                if results and results.get('results'):
                    # Format results for display
                    formatted_results = []
                    for i, result in enumerate(results['results'], 1):
                        title = result.get('title', 'æ— æ ‡é¢˜')
                        snippet = result.get('snippet', 'æ— æ‘˜è¦')
                        url = result.get('url', '')

                        formatted_results.append(f"{i}. {title}")
                        formatted_results.append(f"   {snippet[:150]}...")
                        if url:
                            formatted_results.append(f"   é“¾æ¥: {url}")
                        formatted_results.append("")

                    return "\n".join(formatted_results)
                else:
                    return f"æœç´¢ '{search_query}' æœªæ‰¾åˆ°ç›¸å…³ç»“æœã€‚"

            except Exception as e:
                return f"æœç´¢æ—¶å‡ºé”™: {str(e)}"

        # Fallback to arxiv if tavily is not available
        elif self.arxiv:
            try:
                results = self.arxiv.search(search_query, max_results=2)

                if results and results.get('results'):
                    # Format results for display
                    formatted_results = []
                    for i, result in enumerate(results['results'], 1):
                        title = result.get('title', 'æ— æ ‡é¢˜')
                        snippet = result.get('snippet', 'æ— æ‘˜è¦')
                        url = result.get('url', '')

                        formatted_results.append(f"{i}. {title}")
                        formatted_results.append(f"   {snippet[:150]}...")
                        if url:
                            formatted_results.append(f"   é“¾æ¥: {url}")
                        formatted_results.append("")

                    return f"ä» arXiv æ‰¾åˆ°ä»¥ä¸‹è®ºæ–‡:\n\n" + "\n".join(formatted_results)
                else:
                    return f"æœç´¢ '{search_query}' æœªæ‰¾åˆ°ç›¸å…³è®ºæ–‡ã€‚"

            except Exception as e:
                return f"æœç´¢æ—¶å‡ºé”™: {str(e)}"

        else:
            return "æŠ±æ­‰ï¼Œå½“å‰æ²¡æœ‰å¯ç”¨çš„æœç´¢å·¥å…·ã€‚"

    def _extract_search_query(self, user_input: str) -> str:
        cleaned = re.sub(r'(æœç´¢|search|æŸ¥æ‰¾|find|å…³äº|about)[ï¼š:\s]*', '', user_input)
        cleaned = re.sub(r'[ï¼Ÿ?ï¼!ã€‚.]$', '', cleaned)
        return cleaned.strip()

    # å¤„ç†å¤æ‚ç ”ç©¶ï¼Œä¼šèµ°ä¸»æµç¨‹
    def _handle_complex_research(self, user_input: str) -> str:
        console.print("[yellow]æ­£åœ¨è¿›è¡Œæ·±åº¦ç ”ç©¶ï¼Œè¿™å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´...[/yellow]")
        try:
            from RAgents.agents.coordinator import Coordinator
            from RAgents.agents.planner import Planner
            from RAgents.agents.researcher import Researcher

            coordinator = Coordinator(self.llm)
            planner = Planner(self.llm)
            researcher = Researcher(
                llm=self.llm,
                tavily_api_key=self.config.get('tavily_api_key'),
                mcp_server_url=self.config.get('mcp_server_url'),
                mcp_api_key=self.config.get('mcp_api_key'),
                enable_vector_memory=True,
                vector_memory_path=self.config.get('vector_memory_path', './vector_memory')
            )

            state = coordinator.initialize_research(
                user_input,
                auto_approve=True,  # Auto-approve for conversation mode
                output_format="markdown"
            )
            if state.get('simple_response'):
                return state['simple_response']
            state = planner.create_research_plan(state)
            next_task = planner.get_next_task(state)
            if next_task:
                state = researcher.execute_task(state, next_task)
                relevant_info = researcher.extract_relevant_info(state)

                # Store results in vector memory
                if state.get('research_results'):
                    self.vector_memory.store_research_result(
                        query=user_input,
                        results={'search_results': state['research_results']},
                        quality_score=0.0,  # Will be updated based on feedback
                        metadata={
                            'session_id': self.session_id,
                            'conversation_mode': True
                        }
                    )
                response = (
                    f"æˆ‘å·²å¼€å§‹ç ”ç©¶ '{user_input}'ï¼Œä»¥ä¸‹æ˜¯åˆæ­¥å‘ç°:\n\n"
                    f"{relevant_info}\n\n"
                    "å¦‚æœæ‚¨éœ€è¦æ›´è¯¦ç»†çš„ç ”ç©¶ï¼Œè¯·ä½¿ç”¨å®Œæ•´çš„ç ”ç©¶æ¨¡å¼ã€‚"
                )
                return response
            else:
                return "æ— æ³•ä¸ºæ‚¨çš„æŸ¥è¯¢åˆ¶å®šç ”ç©¶è®¡åˆ’ï¼Œè¯·å°è¯•é‡æ–°è¡¨è¿°æˆ–ä½¿ç”¨æ›´å…·ä½“çš„æè¿°ã€‚"

        except Exception as e:
            return f"æ‰§è¡Œç ”ç©¶æ—¶å‡ºé”™: {str(e)}"

    # å¤„ç†é»˜è®¤å¤šè½®å¯¹è¯ï¼Œé‡‡ç”¨çŸ­æœŸè®°å¿†å’Œå‘é‡åº“
    def _handle_conversation_query(self, user_input: str) -> str:
        # ä»å‘é‡æ•°æ®åº“ä¸­æŸ¥è¯¢æ•°æ®
        similar_reports = self.vector_memory.find_similar_queries(
            user_input,
            threshold=self.relevance_threshold,
            limit=3
        )
        # è·å–å¯¹è¯ä¸Šä¸‹æ–‡
        conversation_context = self._get_conversation_context()
        # è·å–prompt
        prompt = self._prepare_conversation_prompt(
            user_input,
            conversation_context,
            similar_reports
        )
        # è°ƒç”¨LLMç”Ÿæˆå›å¤
        try:
            response = self.llm.generate(prompt, temperature=0.7)
            return response.strip()
        except Exception as e:
            return f"ç”Ÿæˆå›åº”æ—¶å‡ºé”™: {str(e)}"

    def _get_conversation_context(self) -> str:
        if not self.conversation_history:
            return ""
        recent_history = self.conversation_history[-2 * self.context_window:]
        context_parts = []
        for message in recent_history:
            role = "ç”¨æˆ·" if message['role'] == 'user' else "ç³»ç»Ÿ"
            content = message['content']
            context_parts.append(f"{role}: {content}")
        return "\n".join(context_parts)

    def _prepare_conversation_prompt(
            self,
            user_input: str,
            conversation_context: str,
            similar_reports: List[Dict]
    ) -> str:
        prompt_parts = [
            "ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œèƒ½å¤ŸåŸºäºå†å²ç ”ç©¶æŠ¥å‘Šå’Œå¯ç”¨å·¥å…·ä¸ç”¨æˆ·è¿›è¡Œå¤šè½®å¯¹è¯ã€‚",
            "è¯·æ ¹æ®ç”¨æˆ·çš„å½“å‰é—®é¢˜ã€å¯¹è¯å†å²å’Œç›¸å…³å†å²ç ”ç©¶æŠ¥å‘Šï¼Œæä¾›æœ‰ç”¨çš„å›åº”ã€‚",
        ]

        if conversation_context:
            prompt_parts.append("\næœ€è¿‘çš„å¯¹è¯å†å²:")
            prompt_parts.append(conversation_context)

        if similar_reports:
            prompt_parts.append("\nç›¸å…³å†å²ç ”ç©¶æŠ¥å‘Š:")
            for i, report in enumerate(similar_reports, 1):
                prompt_parts.append(f"{i}. æŸ¥è¯¢: {report['query']}")
                prompt_parts.append(f"   ç»“æœæ‘˜è¦: {report['results_summary']}")
                prompt_parts.append(f"   ç›¸ä¼¼åº¦: {report['similarity']:.2f}")

        prompt_parts.append(f"\nå½“å‰ç”¨æˆ·é—®é¢˜: {user_input}")

        prompt_parts.append(
            "\nè¯·åŸºäºä»¥ä¸Šä¿¡æ¯æä¾›æœ‰ç”¨çš„å›åº”ã€‚å¦‚æœå†å²æŠ¥å‘Šä¸­åŒ…å«ç›¸å…³ä¿¡æ¯ï¼Œè¯·å¼•ç”¨ã€‚"
            "å¦‚æœéœ€è¦æœ€æ–°ä¿¡æ¯ï¼Œå¯ä»¥æåŠå¯ä»¥ä½¿ç”¨æœç´¢å·¥å…·è·å–æœ€æ–°æ•°æ®ã€‚"
        )

        return "\n".join(prompt_parts)

